{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "\n",
    "import torch\n",
    "\n",
    "from finn.util.test import get_test_model_trained\n",
    "import brevitas.onnx as bo\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d\n",
    "from QuantLenetV2 import *\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantLinear\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas_examples.bnn_pynq.models.common import CommonWeightQuant, CommonActQuant\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas_examples.bnn_pynq.models.tensor_norm import TensorNorm\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "\n",
    "import netron\n",
    "\n",
    "stopit = lambda: netron.stop(8081, \"0.0.0.0\")\n",
    "\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.stats import StatsOp\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.core.quant import QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_WIDTH = 8\n",
    "WEIGHT_WIDTH = 2\n",
    "ACT_WIDTH = 2\n",
    "MODEL_PREFIX = f\"model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}\"\n",
    "\n",
    "model = cnv(INPUT_WIDTH,WEIGHT_WIDTH,ACT_WIDTH,num_classes=10, in_channels=1)\n",
    "# from QuantLeNet import QuantLeNet\n",
    "# model = QuantLeNet(INPUT_WIDTH, WEIGHT_WIDTH, ACT_WIDTH)\n",
    "path=f\"./models/model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}.pth\"\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/notebooks/LeNet/QuantLenetV2.py:92: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  x = 2.0 * x - torch.tensor([1.0], device=x.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/model_i8_w2_a2_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff32db34470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_dir = './onnx'\n",
    "\n",
    "bo.export_finn_onnx(model, (1, IN_CH, IMG_WIDTH, IMG_HEIGHT), build_dir + f\"/{MODEL_PREFIX}_export.onnx\")\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_export.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_tidy.onnx\")\n",
    "\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/infer_data_layouts.py:113: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i8_w2_a2_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff32dade048>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(build_dir+f\"/{MODEL_PREFIX}_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = build_dir+f\"/{MODEL_PREFIX}_preproc.onnx\"\n",
    "bo.export_finn_onnx(totensor_pyt, ishape, chkpt_preproc_name)\n",
    "\n",
    "# join preprocessing and core model\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType.UINT8)\n",
    "\n",
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "# postprocessing: insert Top-1 node at the end\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = build_dir+f\"/{MODEL_PREFIX}_pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)\n",
    "\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i8_w2_a2_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff3a80a7d68>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "# quantization width greater than 1, so we don't do this\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/model_i8_w2_a2_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff31caea470>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "mem_mode = \"decoupled\"\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "\n",
    "# Not doing Binary Streaming FC Layer because we don't have a BNN\n",
    "model = model.transform(to_hls.InferBinaryStreamingFCLayer(mem_mode))\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer(mem_mode))\n",
    "\n",
    "# TopK to LabelSelect\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "# # input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "# # get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# # get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "# infer tensor data layouts\n",
    "\n",
    "# model = model.transform(InferDataLayouts())\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + f\"/{MODEL_PREFIX}_dataflow_parent.onnx\")\n",
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i8_w2_a2_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff32db1eeb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")\n",
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i8_w2_a2_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff32dc555f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto-folding did not succeed. It resulted in an error further downstream\n",
    "# from finn.transformation.fpgadataflow.set_folding import SetFolding\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")\n",
    "\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# print(len(fc_layers))\n",
    "\n",
    "# print (fc_layers[2])\n",
    "\n",
    "folding = [\n",
    "    (16, 1, 128),\n",
    "    (16, 16, 128),\n",
    "    (16, 16, 128),\n",
    "    (16, 16, 128),\n",
    "    (1, 16, 2),\n",
    "    (1, 4, 2),\n",
    "    (1, 8, 128),\n",
    "    (5, 1, 1),\n",
    "]\n",
    "for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififodepth)\n",
    "\n",
    "# use same SIMD values for the sliding window operators\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "for i in range(len(swg_layers)):\n",
    "    swg_inst = getCustomOp(swg_layers[i])\n",
    "    simd = folding[i][1]\n",
    "    swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "\n",
    "# folded_model = dataflow_model.transform(SetFolding())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_folded.onnx\")\n",
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "stopit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2845a0b6d9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpgadataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_zynq_proj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZynqBuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_dir\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34mf\"/{MODEL_PREFIX}_folded.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZynqBuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pynq_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_clk_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_dir\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34mf\"/{MODEL_PREFIX}_synth.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             )\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/transformation/fpgadataflow/make_zynq_proj.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mPrepareIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpga_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mkernel_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHLSSynthIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             kernel_model = kernel_model.transform(\n\u001b[1;32m    305\u001b[0m                 CreateStitchedIP(\n",
      "\u001b[0;32m/workspace/finn/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             )\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/transformation/__init__.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Execute transformation in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mnew_nodes_and_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplyNodeLocal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# extract nodes and check if the transformation needs to run again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_pynq_board = \"Pynq-Z2\"\n",
    "target_clk_ns = 10\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir+ f\"/{MODEL_PREFIX}_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = test_pynq_board, period_ns = target_clk_ns))\n",
    "model.save(build_dir +  f\"/{MODEL_PREFIX}_synth.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "# set up the following values according to your own environment\n",
    "# FINN will use ssh to deploy and run the generated accelerator\n",
    "ip = os.getenv(\"PYNQ_IP\", \"192.168.254.35\")\n",
    "username = os.getenv(\"PYNQ_USERNAME\", \"xilinx\")\n",
    "password = os.getenv(\"PYNQ_PASSWORD\", \"xilinx\")\n",
    "port = os.getenv(\"PYNQ_PORT\", 22)\n",
    "target_dir = os.getenv(\"PYNQ_TARGET_DIR\", \"/home/xilinx/finn_cnv_end2end_example\")\n",
    "ipAdd = \"192.168.254.35\"\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_synth.onnx\")\n",
    "model = model.transform(DeployToPYNQ(ipAdd, port, username, password, target_dir))\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_pynqZ2_deploy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xilinx/finn_dev_nojan/pynq_deployment_xnf6m4pl'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dir_pynq = target_dir + \"/\" + model.get_metadata_prop(\"pynq_deployment_dir\").split(\"/\")[-1]\n",
    "target_dir_pynq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4232\r\n",
      "-rw-r--r-- 1 xilinx xilinx    8512 Dec 16 04:45 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Dec 16 03:55 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx    3264 Dec 16 04:49 input.npy\r\n",
      "-rw-r--r-- 1 root   root       206 Dec 16 04:54 nw_metrics.txt\r\n",
      "-rw-r--r-- 1 root   root        84 Dec 16 04:49 output.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 4045671 Dec 16 03:55 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  247307 Dec 16 03:55 resizer.hwh\r\n",
      "-rw-r--r-- 1 root   root        32 Dec 16 04:54 sds_trace_data.dat\r\n",
      "-rw-r--r-- 1 xilinx xilinx    1727 Dec 16 03:55 validate.py\r\n"
     ]
    }
   ],
   "source": [
    "! sshpass -p {password} ssh {username}@192.168.254.35 -p {port} 'ls -l {target_dir_pynq}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff31c7bacf8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pkgutil import get_data\n",
    "import onnx.numpy_helper as nph\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "DATASET_ROOT = \"/workspace/finn/src/data/fashion\"\n",
    "test_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "testImage = images[30]\n",
    "plt.imshow(testImage.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected network input shape is [1, 28, 28, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bag'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_pynqZ2_deploy.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "print(\"Expected network input shape is \" + str(ishape))\n",
    "\n",
    "import numpy as np\n",
    "import bitstring\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "\n",
    "test = testImage[0].numpy()*255\n",
    "\n",
    "input_dict = {iname: test.reshape(ishape)}\n",
    "ret = execute_onnx(model, input_dict, False)\n",
    "\n",
    "classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', \\\n",
    "           'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
    "\n",
    "classes[int(ret[\"global_out\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network metrics:\n",
      "runtime[ms]: 971.9593524932861\n",
      "throughput[images/s]: 10288.496092298341\n",
      "DRAM_in_bandwidth[Mb/s]: 8.0661809363619\n",
      "DRAM_out_bandwidth[Mb/s]: 0.01028849609229834\n",
      "fclk[mhz]: 100.0\n",
      "N: 10000\n"
     ]
    }
   ],
   "source": [
    "from finn.core.throughput_test import throughput_test_remote\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_pynqZ2_deploy.onnx\")\n",
    "res = throughput_test_remote(model, 10000)\n",
    "print(\"Network metrics:\")\n",
    "for key in res:\n",
    "    print(str(key) + \": \" + str(res[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
