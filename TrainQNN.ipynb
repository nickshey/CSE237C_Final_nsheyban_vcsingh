{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from QuantLeNet import QuantLeNet\n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/workspace/finn/src/data/fashion\"\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# percentage of training data\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /workspace/finn/src/data/fashion/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 26402816/26421880 [00:21<00:00, 1865871.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /workspace/finn/src/data/fashion/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /workspace/finn/src/data/fashion/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/29515 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▌    | 16384/29515 [00:00<00:00, 121296.56it/s]\u001b[A\n",
      "32768it [00:00, 69955.34it/s]                            \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /workspace/finn/src/data/fashion/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /workspace/finn/src/data/fashion/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4422102 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/4422102 [00:00<00:35, 122788.34it/s]\u001b[A\n",
      "  1%|          | 49152/4422102 [00:00<00:30, 145478.95it/s]\u001b[A\n",
      "  2%|▏         | 106496/4422102 [00:00<00:23, 181032.99it/s]\u001b[A\n",
      "  5%|▌         | 229376/4422102 [00:00<00:17, 238162.06it/s]\u001b[A\n",
      " 11%|█         | 466944/4422102 [00:01<00:12, 312056.09it/s]\u001b[A\n",
      " 21%|██        | 925696/4422102 [00:01<00:08, 421270.48it/s]\u001b[A\n",
      " 40%|████      | 1777664/4422102 [00:01<00:04, 585930.03it/s]\u001b[A\n",
      " 51%|█████     | 2260992/4422102 [00:01<00:02, 794667.52it/s]\u001b[A\n",
      " 60%|██████    | 2670592/4422102 [00:01<00:01, 1047723.66it/s]\u001b[A\n",
      " 74%|███████▍  | 3284992/4422102 [00:01<00:00, 1390651.47it/s]\u001b[A\n",
      " 87%|████████▋ | 3850240/4422102 [00:01<00:00, 1680772.91it/s]\u001b[A\n",
      "4423680it [00:01, 2383744.14it/s]                             \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /workspace/finn/src/data/fashion/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /workspace/finn/src/data/fashion/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5148 [00:00<?, ?it/s]\u001b[A\n",
      "8192it [00:00, 26253.30it/s]            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /workspace/finn/src/data/fashion/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, download=True, train=True, transform=transform)\n",
    "val_data, train_data = torch.utils.data.random_split(train_data, [50000, 10000])\n",
    "test_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', \\\n",
    "           'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY MODIFY CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 8\n",
    "WEIGHT_WIDTH = 4\n",
    "ACT_WIDTH = 8\n",
    "\n",
    "MAX_EPOCHS = 10\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY MODIFY CELL ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = QuantLeNet(input_width=INPUT_WIDTH, weight_width=WEIGHT_WIDTH, act_width=ACT_WIDTH)\n",
    "path = f\"./models/model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 2.29934022\n",
      "[1,   100] loss: 2.28473729\n",
      "[1,   150] loss: 2.20373415\n",
      "[1,   200] loss: 1.87654436\n",
      "[1,   250] loss: 1.42193369\n",
      "[1,   300] loss: 1.18033038\n",
      "[1,   350] loss: 1.06097368\n",
      "[1,   400] loss: 0.98448684\n",
      "[1,   450] loss: 0.93623336\n",
      "[1,   500] loss: 0.90983144\n",
      "[1,   550] loss: 0.88010255\n",
      "[1,   600] loss: 0.87537523\n",
      "[1,   650] loss: 0.84561798\n",
      "[1,   700] loss: 0.82130677\n",
      "[1,   750] loss: 0.80353519\n",
      "[1,   800] loss: 0.79559470\n",
      "[1,   850] loss: 0.80612380\n",
      "[1,   900] loss: 0.77534429\n",
      "[1,   950] loss: 0.76289889\n",
      "[1,  1000] loss: 0.78041349\n",
      "New Best Validation:[epoch #1] loss: 0.77033142\n",
      "[2,    50] loss: 0.77127213\n",
      "[2,   100] loss: 0.75429023\n",
      "[2,   150] loss: 0.75584762\n",
      "[2,   200] loss: 0.74571512\n",
      "[2,   250] loss: 0.71015889\n",
      "[2,   300] loss: 0.71462387\n",
      "[2,   350] loss: 0.70562144\n",
      "[2,   400] loss: 0.72162543\n",
      "[2,   450] loss: 0.66395408\n",
      "[2,   500] loss: 0.69297022\n",
      "[2,   550] loss: 0.69196573\n",
      "[2,   600] loss: 0.69262882\n",
      "[2,   650] loss: 0.69497211\n",
      "[2,   700] loss: 0.68489933\n",
      "[2,   750] loss: 0.65613603\n",
      "[2,   800] loss: 0.69649584\n",
      "[2,   850] loss: 0.65809140\n",
      "[2,   900] loss: 0.64772176\n",
      "[2,   950] loss: 0.65166609\n",
      "[2,  1000] loss: 0.66595298\n",
      "New Best Validation:[epoch #2] loss: 0.66664884\n",
      "[3,    50] loss: 0.66493654\n",
      "[3,   100] loss: 0.63741364\n",
      "[3,   150] loss: 0.63125280\n",
      "[3,   200] loss: 0.66278837\n",
      "[3,   250] loss: 0.65159798\n",
      "[3,   300] loss: 0.65800380\n",
      "[3,   350] loss: 0.63438059\n",
      "[3,   400] loss: 0.63120829\n",
      "[3,   450] loss: 0.60492701\n",
      "[3,   500] loss: 0.63189427\n",
      "[3,   550] loss: 0.63132792\n",
      "[3,   600] loss: 0.61846969\n",
      "[3,   650] loss: 0.64071828\n",
      "[3,   700] loss: 0.62263694\n",
      "[3,   750] loss: 0.61722658\n",
      "[3,   800] loss: 0.61718574\n",
      "[3,   850] loss: 0.58292994\n",
      "[3,   900] loss: 0.60711023\n",
      "[3,   950] loss: 0.60857656\n",
      "[3,  1000] loss: 0.63589762\n",
      "New Best Validation:[epoch #3] loss: 0.61664292\n",
      "[4,    50] loss: 0.60906673\n",
      "[4,   100] loss: 0.59713701\n",
      "[4,   150] loss: 0.60508574\n",
      "[4,   200] loss: 0.61090520\n",
      "[4,   250] loss: 0.60956048\n",
      "[4,   300] loss: 0.61096723\n",
      "[4,   350] loss: 0.61394806\n",
      "[4,   400] loss: 0.59720776\n",
      "[4,   450] loss: 0.59848148\n",
      "[4,   500] loss: 0.56002090\n",
      "[4,   550] loss: 0.57285036\n",
      "[4,   600] loss: 0.61798587\n",
      "[4,   650] loss: 0.56985364\n",
      "[4,   700] loss: 0.57301494\n",
      "[4,   750] loss: 0.57649004\n",
      "[4,   800] loss: 0.56352711\n",
      "[4,   850] loss: 0.55146830\n",
      "[4,   900] loss: 0.59873436\n",
      "[4,   950] loss: 0.58219267\n",
      "[4,  1000] loss: 0.55408728\n",
      "New Best Validation:[epoch #4] loss: 0.57852928\n",
      "[5,    50] loss: 0.56930119\n",
      "[5,   100] loss: 0.58097658\n",
      "[5,   150] loss: 0.56396229\n",
      "[5,   200] loss: 0.55151630\n",
      "[5,   250] loss: 0.60065068\n",
      "[5,   300] loss: 0.56763920\n",
      "[5,   350] loss: 0.52664767\n",
      "[5,   400] loss: 0.54025970\n",
      "[5,   450] loss: 0.57868177\n",
      "[5,   500] loss: 0.57270569\n",
      "[5,   550] loss: 0.53141840\n",
      "[5,   600] loss: 0.56510870\n",
      "[5,   650] loss: 0.55579399\n",
      "[5,   700] loss: 0.54445372\n",
      "[5,   750] loss: 0.54637663\n",
      "[5,   800] loss: 0.56019539\n",
      "[5,   850] loss: 0.57546502\n",
      "[5,   900] loss: 0.54244973\n",
      "[5,   950] loss: 0.53513525\n",
      "[5,  1000] loss: 0.53731238\n",
      "New Best Validation:[epoch #5] loss: 0.56239115\n",
      "[6,    50] loss: 0.53750036\n",
      "[6,   100] loss: 0.55415416\n",
      "[6,   150] loss: 0.54281684\n",
      "[6,   200] loss: 0.51848621\n",
      "[6,   250] loss: 0.54027754\n",
      "[6,   300] loss: 0.56215619\n",
      "[6,   350] loss: 0.51346045\n",
      "[6,   400] loss: 0.52329229\n",
      "[6,   450] loss: 0.54598811\n",
      "[6,   500] loss: 0.54896546\n",
      "[6,   550] loss: 0.52923137\n",
      "[6,   600] loss: 0.52160719\n",
      "[6,   650] loss: 0.53728384\n",
      "[6,   700] loss: 0.53937526\n",
      "[6,   750] loss: 0.51714278\n",
      "[6,   800] loss: 0.54717276\n",
      "[6,   850] loss: 0.53103304\n",
      "[6,   900] loss: 0.52207661\n",
      "[6,   950] loss: 0.53262830\n",
      "[6,  1000] loss: 0.52073219\n",
      "New Best Validation:[epoch #6] loss: 0.53225573\n",
      "[7,    50] loss: 0.50350147\n",
      "[7,   100] loss: 0.54445019\n",
      "[7,   150] loss: 0.50559161\n",
      "[7,   200] loss: 0.51696864\n",
      "[7,   250] loss: 0.51997520\n",
      "[7,   300] loss: 0.53255995\n",
      "[7,   350] loss: 0.51140410\n",
      "[7,   400] loss: 0.51589347\n",
      "[7,   450] loss: 0.52143248\n",
      "[7,   500] loss: 0.53139524\n",
      "[7,   550] loss: 0.51157072\n",
      "[7,   600] loss: 0.48064719\n",
      "[7,   650] loss: 0.51234510\n",
      "[7,   700] loss: 0.51103576\n",
      "[7,   750] loss: 0.52122747\n",
      "[7,   800] loss: 0.48634308\n",
      "[7,   850] loss: 0.49687282\n",
      "[7,   900] loss: 0.48842783\n",
      "[7,   950] loss: 0.48589073\n",
      "[7,  1000] loss: 0.51206118\n",
      "New Best Validation:[epoch #7] loss: 0.50008431\n",
      "[8,    50] loss: 0.48391877\n",
      "[8,   100] loss: 0.52552723\n",
      "[8,   150] loss: 0.50039463\n",
      "[8,   200] loss: 0.51103460\n",
      "[8,   250] loss: 0.46223220\n",
      "[8,   300] loss: 0.51892995\n",
      "[8,   350] loss: 0.49684300\n",
      "[8,   400] loss: 0.49524535\n",
      "[8,   450] loss: 0.47561283\n",
      "[8,   500] loss: 0.50755050\n",
      "[8,   550] loss: 0.46655130\n",
      "[8,   600] loss: 0.48408277\n",
      "[8,   650] loss: 0.47872580\n",
      "[8,   700] loss: 0.48363266\n",
      "[8,   750] loss: 0.47851904\n",
      "[8,   800] loss: 0.47300174\n",
      "[8,   850] loss: 0.48094065\n",
      "[8,   900] loss: 0.50080589\n",
      "[8,   950] loss: 0.48744702\n",
      "[8,  1000] loss: 0.49029798\n",
      "New Best Validation:[epoch #8] loss: 0.49663741\n",
      "[9,    50] loss: 0.46424495\n",
      "[9,   100] loss: 0.46630460\n",
      "[9,   150] loss: 0.47106972\n",
      "[9,   200] loss: 0.47593664\n",
      "[9,   250] loss: 0.49042444\n",
      "[9,   300] loss: 0.46207406\n",
      "[9,   350] loss: 0.47284318\n",
      "[9,   400] loss: 0.45332236\n",
      "[9,   450] loss: 0.46688936\n",
      "[9,   500] loss: 0.47025745\n",
      "[9,   550] loss: 0.48799246\n",
      "[9,   600] loss: 0.46399601\n",
      "[9,   650] loss: 0.44058891\n",
      "[9,   700] loss: 0.47833077\n",
      "[9,   750] loss: 0.49651451\n",
      "[9,   800] loss: 0.46718837\n",
      "[9,   850] loss: 0.46414730\n",
      "[9,   900] loss: 0.47761125\n",
      "[9,   950] loss: 0.50413733\n",
      "[9,  1000] loss: 0.47733865\n",
      "New Best Validation:[epoch #9] loss: 0.47207061\n",
      "[10,    50] loss: 0.47439699\n",
      "[10,   100] loss: 0.46084787\n",
      "[10,   150] loss: 0.46738429\n",
      "[10,   200] loss: 0.47676725\n",
      "[10,   250] loss: 0.45907404\n",
      "[10,   300] loss: 0.45458300\n",
      "[10,   350] loss: 0.46582079\n",
      "[10,   400] loss: 0.46633763\n",
      "[10,   450] loss: 0.46048010\n",
      "[10,   500] loss: 0.47200245\n",
      "[10,   550] loss: 0.45229292\n",
      "[10,   600] loss: 0.43849319\n",
      "[10,   650] loss: 0.44109855\n",
      "[10,   700] loss: 0.44196845\n",
      "[10,   750] loss: 0.44213501\n",
      "[10,   800] loss: 0.48785749\n",
      "[10,   850] loss: 0.45716153\n",
      "[10,   900] loss: 0.43676119\n",
      "[10,   950] loss: 0.44214745\n",
      "[10,  1000] loss: 0.47627654\n",
      "New Best Validation:[epoch #10] loss: 0.46592467\n"
     ]
    }
   ],
   "source": [
    "best_model_weights = trainModel(qnet, MAX_EPOCHS, trainloader, valloader, path, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy of t-shirt/top : 82 %\n",
      "Accuracy of trouser : 95 %\n",
      "Accuracy of pullover : 85 %\n",
      "Accuracy of dress : 88 %\n",
      "Accuracy of  coat : 68 %\n",
      "Accuracy of sandal : 92 %\n",
      "Accuracy of shirt : 20 %\n",
      "Accuracy of sneaker : 94 %\n",
      "Accuracy of   bag : 94 %\n",
      "Accuracy of ankle boot : 94 %\n"
     ]
    }
   ],
   "source": [
    "test(path, qnet, testloader, BATCH_SIZE, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
