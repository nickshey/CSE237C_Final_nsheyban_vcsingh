{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from QuantLeNet import QuantLeNet\n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/workspace/finn/src/data/fashion\"\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# percentage of training data\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, download=True, train=True, transform=transform)\n",
    "val_data, train_data = torch.utils.data.random_split(train_data, [50000, 10000])\n",
    "test_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', \\\n",
    "           'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY MODIFY CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 8\n",
    "WEIGHT_WIDTH = 4\n",
    "ACT_WIDTH = 8\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY MODIFY CELL ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = QuantLeNet(input_width=INPUT_WIDTH, weight_width=WEIGHT_WIDTH, act_width=ACT_WIDTH)\n",
    "path = f\"./models/model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 2.29406555\n",
      "[1,   100] loss: 2.25706749\n",
      "[1,   150] loss: 2.11781415\n",
      "[1,   200] loss: 1.75722657\n",
      "[1,   250] loss: 1.40498899\n",
      "[1,   300] loss: 1.21137194\n"
     ]
    }
   ],
   "source": [
    "best_model_weights = trainModel(qnet, MAX_EPOCHS, trainloader, valloader, path, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy of t-shirt/top : 82 %\n",
      "Accuracy of trouser : 95 %\n",
      "Accuracy of pullover : 85 %\n",
      "Accuracy of dress : 88 %\n",
      "Accuracy of  coat : 68 %\n",
      "Accuracy of sandal : 92 %\n",
      "Accuracy of shirt : 20 %\n",
      "Accuracy of sneaker : 94 %\n",
      "Accuracy of   bag : 94 %\n",
      "Accuracy of ankle boot : 94 %\n"
     ]
    }
   ],
   "source": [
    "test(path, qnet, testloader, BATCH_SIZE, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
