{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "import brevitas.onnx as bo\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d\n",
    "from QuantLeNet import *\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantLinear\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas_examples.bnn_pynq.models.common import CommonWeightQuant, CommonActQuant\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas_examples.bnn_pynq.models.tensor_norm import TensorNorm\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "\n",
    "import netron\n",
    "\n",
    "stopit = lambda: netron.stop(8081, \"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {666: (6,6,6), 848: (8,4,8), 888: (8,8,8)}\n",
    "\n",
    "INPUT_WIDTH, WEIGHT_WIDTH, ACT_WIDTH = sizes[666]\n",
    "\n",
    "build_dir = \"./onnx\"\n",
    "MODEL_PREFIX = f\"model_norelu_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantLeNetMinusRelu(INPUT_WIDTH,WEIGHT_WIDTH,ACT_WIDTH)\n",
    "# path=f\"./models/model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}.pth\"\n",
    "# model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/model_norelu_i6_w6_a6_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f366dc96f98>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.export_finn_onnx(model, (1, 1, 28, 28), build_dir + f\"/{MODEL_PREFIX}_export.onnx\")\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_export.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_tidy.onnx\")\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/infer_data_layouts.py:113: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(build_dir+f\"/{MODEL_PREFIX}_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = build_dir+f\"/{MODEL_PREFIX}_preproc.onnx\"\n",
    "bo.export_finn_onnx(totensor_pyt, ishape, chkpt_preproc_name)\n",
    "\n",
    "# join preprocessing and core model\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType.UINT8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_norelu_i6_w6_a6_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f36e810fc88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "# postprocessing: insert Top-1 node at the end\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = build_dir+f\"/{MODEL_PREFIX}_pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)\n",
    "\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "# model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_norelu_i6_w6_a6_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f366dc21b38>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "stopit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "mem_mode = \"decoupled\"\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "# model = model.transform(to_hls.InferBinaryStreamingFCLayer(mem_mode))\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer(mem_mode))\n",
    "\n",
    "\n",
    "# TopK to LabelSelect\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "# # input quantization (if any) to standalone thresholding\n",
    "# model = model.transform(to_hls.InferThresholdingLayer())\n",
    "# model = model.transform(to_hls.InferConvInpGen())\n",
    "# model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "# # get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# # get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "# infer tensor data layouts\n",
    "\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + f\"/{MODEL_PREFIX}_dataflow_parent.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_norelu_i6_w6_a6_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f366dc7a320>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "stopit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_qi_i6_w6_a6_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fda38958278>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "netron.stop(8081, \"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# each tuple is (PE, SIMD, in_fifo_depth) for a layer\n",
    "\n",
    "# what are FIFO depths? Time to check the paper\n",
    "folding = [\n",
    "    (16, 1, 128),\n",
    "    (32, 32, 128),\n",
    "    (16, 32, 128),\n",
    "]\n",
    "for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififodepth)\n",
    "\n",
    "# use same SIMD values for the sliding window operators\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "for i in range(len(swg_layers)):\n",
    "    swg_inst = getCustomOp(swg_layers[i])\n",
    "    simd = folding[i][1]\n",
    "    ifm_ch = folding[i][-1]\n",
    "    swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "#     swg_inst.set_nodeattr(\"IFMChannels\", ifm_ch)\n",
    "\n",
    "\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(build_dir + f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pynq_board = \"Pynq-Z1\"\n",
    "target_clk_ns = 10\n",
    "\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir+f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /workspace/finn/src/finn/transformation/fpgadataflow/make_zynq_proj.py(208)apply()\n",
      "-> \n"
     ]
    }
   ],
   "source": [
    "import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<finn.transformation.fpgadataflow.make_pynq_driver.MakePYNQDriver object at 0x7fda38a3ee10>\n",
      "starting <finn.transformation.fpgadataflow.make_pynq_driver.MakePYNQDriver object at 0x7fda38a3ee10>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Datatype DataType.FLOAT32 is not supported, no tensor could be generated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b7b3cbe6e4a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZynqBuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pynq_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_clk_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"/{MODEL_PREFIX}_synth.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             )\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/transformation/fpgadataflow/make_zynq_proj.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"starting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGiveUniqueNodeNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGiveReadableTensorNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             )\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/transformation/fpgadataflow/make_pynq_driver.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# generate dummy folded i/o tensors and their packed versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mi_tensor_dummy_folded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_finn_dt_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_tensor_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_tensor_shape_folded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mo_tensor_dummy_folded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_finn_dt_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_tensor_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_tensor_shape_folded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         i_tensor_dummy_packed = finnpy_to_packed_bytearray(\n",
      "\u001b[0;32m/workspace/finn/src/finn/util/basic.py\u001b[0m in \u001b[0;36mgen_finn_dt_tensor\u001b[0;34m(finn_dt, tensor_shape)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise ValueError(\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0;34m\"Datatype {} is not supported, no tensor could be generated\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinn_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         )\n\u001b[1;32m    312\u001b[0m     \u001b[0;31m# always use float type as container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Datatype DataType.FLOAT32 is not supported, no tensor could be generated"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model.transform(ZynqBuild(platform = test_pynq_board, period_ns = target_clk_ns))\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_synth.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9924b9a7f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pkgutil import get_data\n",
    "import onnx.numpy_helper as nph\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "DATASET_ROOT = \"/workspace/finn/src/data/fashion\"\n",
    "test_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "testImage = images[2]\n",
    "plt.imshow(testImage.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected network input shape is [1, 1, 28, 28]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trouser'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "print(\"Expected network input shape is \" + str(ishape))\n",
    "\n",
    "import numpy as np\n",
    "import bitstring\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "\n",
    "test = testImage[0].numpy()*255\n",
    "\n",
    "input_dict = {iname: test.reshape(ishape)}\n",
    "ret = execute_onnx(model, input_dict)\n",
    "\n",
    "classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', \\\n",
    "           'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
    "\n",
    "classes[ret[\"global_out\"][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected network input shape is [1, 28, 28, 1]\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "print(\"Expected network input shape is \" + str(ishape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
