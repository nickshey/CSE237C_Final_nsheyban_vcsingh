{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "import brevitas.onnx as bo\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d\n",
    "from QuantLeNet import QuantLeNet\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantLinear\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas_examples.bnn_pynq.models.common import CommonWeightQuant, CommonActQuant\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas_examples.bnn_pynq.models.tensor_norm import TensorNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {666: (6,6,6), 848: (8,4,8), 888: (8,8,8)}\n",
    "\n",
    "INPUT_WIDTH, WEIGHT_WIDTH, ACT_WIDTH = sizes[666]\n",
    "\n",
    "build_dir = \"./onnx\"\n",
    "MODEL_PREFIX = f\"model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QuantLeNet(INPUT_WIDTH,WEIGHT_WIDTH,ACT_WIDTH)\n",
    "path=f\"./models/model_i{INPUT_WIDTH}_w{WEIGHT_WIDTH}_a{ACT_WIDTH}.pth\"\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i6_w6_a6_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0dbdf66ac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.export_finn_onnx(model, (1, 1, 28, 28), build_dir + f\"/{MODEL_PREFIX}_export.onnx\")\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_export.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_tidy.onnx\")\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/infer_data_layouts.py:113: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(build_dir+f\"/{MODEL_PREFIX}_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = build_dir+f\"/{MODEL_PREFIX}_preproc.onnx\"\n",
    "bo.export_finn_onnx(totensor_pyt, ishape, chkpt_preproc_name)\n",
    "\n",
    "# join preprocessing and core model\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType.UINT8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i6_w6_a6_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e38d62e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "# postprocessing: insert Top-1 node at the end\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = build_dir+f\"/{MODEL_PREFIX}_pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)\n",
    "\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i6_w6_a6_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0dc010cb38>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "showInNetron(build_dir+f\"/{MODEL_PREFIX}_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/fpgadataflow/convert_to_hls_layers.py:64: UserWarning: Input is not int. Can't infer ConvInpGen\n",
      "  warnings.warn(\"Input is not int. Can't infer ConvInpGen\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "mem_mode = \"decoupled\"\n",
    "\n",
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "model = model.transform(to_hls.InferBinaryStreamingFCLayer(mem_mode))\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer(mem_mode))\n",
    "# TopK to LabelSelect\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "# get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + f\"/{MODEL_PREFIX}_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i6_w6_a6_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e38d624e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/model_i6_w6_a6_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0dbdf662b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[input: \"MultiThreshold_2_out0\"\n",
       " input: \"MatMul_3_param0\"\n",
       " input: \"MultiThreshold_3_param0\"\n",
       " output: \"MultiThreshold_3_out0\"\n",
       " op_type: \"StreamingFCLayer_Batch\"\n",
       " attribute {\n",
       "   name: \"ActVal\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"MH\"\n",
       "   i: 84\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"MW\"\n",
       "   i: 120\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"PE\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"SIMD\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"backend\"\n",
       "   s: \"fpgadataflow\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"binaryXnorMode\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"inputDataType\"\n",
       "   s: \"UINT6\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"mem_mode\"\n",
       "   s: \"decoupled\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"noActivation\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"numInputVectors\"\n",
       "   ints: 1\n",
       "   type: INTS\n",
       " }\n",
       " attribute {\n",
       "   name: \"outputDataType\"\n",
       "   s: \"UINT6\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"resType\"\n",
       "   s: \"ap_resource_lut()\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"weightDataType\"\n",
       "   s: \"INT6\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"accDataType\"\n",
       "   s: \"INT19\"\n",
       "   type: STRING\n",
       " }\n",
       " domain: \"finn\", input: \"Im2Col_0_out0\"\n",
       " input: \"MatMul_0_param0\"\n",
       " output: \"Fj68YG\"\n",
       " op_type: \"StreamingFCLayer_Batch\"\n",
       " attribute {\n",
       "   name: \"ActVal\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"MH\"\n",
       "   i: 6\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"MW\"\n",
       "   i: 25\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"PE\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"SIMD\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"backend\"\n",
       "   s: \"fpgadataflow\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"binaryXnorMode\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"inputDataType\"\n",
       "   s: \"UINT8\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"mem_mode\"\n",
       "   s: \"decoupled\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"noActivation\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"numInputVectors\"\n",
       "   ints: 1\n",
       "   ints: 24\n",
       "   ints: 24\n",
       "   type: INTS\n",
       " }\n",
       " attribute {\n",
       "   name: \"outputDataType\"\n",
       "   s: \"INT24\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"resType\"\n",
       "   s: \"ap_resource_lut()\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"weightDataType\"\n",
       "   s: \"INT6\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"accDataType\"\n",
       "   s: \"INT24\"\n",
       "   type: STRING\n",
       " }\n",
       " domain: \"finn\", input: \"MultiThreshold_3_out0\"\n",
       " input: \"MatMul_4_param0\"\n",
       " output: \"MatMul_4_out0\"\n",
       " op_type: \"StreamingFCLayer_Batch\"\n",
       " attribute {\n",
       "   name: \"ActVal\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"MH\"\n",
       "   i: 10\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"MW\"\n",
       "   i: 84\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"PE\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"SIMD\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"backend\"\n",
       "   s: \"fpgadataflow\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"binaryXnorMode\"\n",
       "   i: 0\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"inputDataType\"\n",
       "   s: \"UINT6\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"mem_mode\"\n",
       "   s: \"decoupled\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"noActivation\"\n",
       "   i: 1\n",
       "   type: INT\n",
       " }\n",
       " attribute {\n",
       "   name: \"numInputVectors\"\n",
       "   ints: 1\n",
       "   type: INTS\n",
       " }\n",
       " attribute {\n",
       "   name: \"outputDataType\"\n",
       "   s: \"INT24\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"resType\"\n",
       "   s: \"ap_resource_lut()\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"weightDataType\"\n",
       "   s: \"INT6\"\n",
       "   type: STRING\n",
       " }\n",
       " attribute {\n",
       "   name: \"accDataType\"\n",
       "   s: \"INT24\"\n",
       "   type: STRING\n",
       " }\n",
       " domain: \"finn\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_dataflow_model.onnx\")\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# each tuple is (PE, SIMD, in_fifo_depth) for a layer\n",
    "fc_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fc_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = getCustomOp(fc_layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PE': ('i', True, 0),\n",
       " 'SIMD': ('i', True, 0),\n",
       " 'MW': ('i', True, 0),\n",
       " 'MH': ('i', True, 0),\n",
       " 'resType': ('s', True, ''),\n",
       " 'ActVal': ('i', False, 0),\n",
       " 'inputDataType': ('s', True, ''),\n",
       " 'weightDataType': ('s', True, ''),\n",
       " 'outputDataType': ('s', True, ''),\n",
       " 'accDataType': ('s', False, 'INT32'),\n",
       " 'binaryXnorMode': ('i', False, 0),\n",
       " 'noActivation': ('i', False, 0),\n",
       " 'numInputVectors': ('ints', False, [1]),\n",
       " 'mem_mode': ('s', False, 'const'),\n",
       " 'ram_style': ('s', False, 'auto'),\n",
       " 'backend': ('s', True, 'fpgadataflow'),\n",
       " 'code_gen_dir_cppsim': ('s', False, ''),\n",
       " 'code_gen_dir_ipgen': ('s', False, ''),\n",
       " 'executable_path': ('s', False, ''),\n",
       " 'ipgen_path': ('s', False, ''),\n",
       " 'ip_path': ('s', False, ''),\n",
       " 'ip_vlnv': ('s', False, ''),\n",
       " 'exec_mode': ('s', False, ''),\n",
       " 'cycles_rtlsim': ('i', False, 0),\n",
       " 'cycles_estimate': ('i', False, 0),\n",
       " 'rtlsim_trace': ('s', False, ''),\n",
       " 'res_estimate': ('s', False, ''),\n",
       " 'res_hls': ('s', False, ''),\n",
       " 'res_synth': ('s', False, ''),\n",
       " 'rtlsim_so': ('s', False, ''),\n",
       " 'partition_id': ('i', False, 0),\n",
       " 'inFIFODepth': ('i', False, 2),\n",
       " 'outFIFODepth': ('i', False, 2)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.get_nodeattr_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<finn.custom_op.fpgadataflow.streamingfclayer_batch.StreamingFCLayer_Batch at 0x7feebd285da0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are FIFO depths? Time to check the paper\n",
    "folding = [\n",
    "    (16, 4, 128),\n",
    "    (32, 32, 128),\n",
    "    (16, 32, 128),\n",
    "]\n",
    "for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififodepth)\n",
    "\n",
    "# use same SIMD values for the sliding window operators\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "for i in range(len(swg_layers)):\n",
    "    swg_inst = getCustomOp(swg_layers[i])\n",
    "    simd = folding[i][1]\n",
    "    ifm_ch = folding[i][-1]\n",
    "    swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    swg_inst.set_nodeattr(\"IFMChannels\", ifm_ch)\n",
    "\n",
    "\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/model_i6_w6_a6_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7feebd298748>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pynq_board = \"Pynq-Z1\"\n",
    "target_clk_ns = 10\n",
    "\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir+f\"/{MODEL_PREFIX}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-75fb5db00f60>(20)<module>()\n",
      "-> swg_layers.set_nodeattr(\"IFMChannels\", ifm_ch)\n",
      "(Pdb) \n"
     ]
    }
   ],
   "source": [
    "import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model.transform(ZynqBuild(platform = test_pynq_board, period_ns = target_clk_ns))\n",
    "model.save(build_dir + f\"/{MODEL_PREFIX}_synth.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkgutil import get_data\n",
    "import onnx.numpy_helper as nph\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "DATASET_ROOT = \"/workspace/finn/src/data/fashion\"\n",
    "test_data = torchvision.datasets.FashionMNIST(DATASET_ROOT, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "testImage = images[2]\n",
    "plt.imshow(testImage.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + f\"/{MODEL_PREFIX}_streamlined.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "print(\"Expected network input shape is \" + str(ishape))\n",
    "\n",
    "import numpy as np\n",
    "import bitstring\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "\n",
    "test = testImage[0].numpy()*255\n",
    "\n",
    "input_dict = {iname: test.reshape(ishape)}\n",
    "ret = execute_onnx(model, input_dict)\n",
    "\n",
    "classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', \\\n",
    "           'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
    "\n",
    "classes[ret[\"global_out\"][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
